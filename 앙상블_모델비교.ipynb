{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a1ec6d9-fc3a-4e30-927a-f5946d6af66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54feb0bf-1438-4fa7-b74a-240e2bb8f787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Wip Line_Dam Process Desc._Dam     Equipment_Dam Model.Suffix_Dam  \\\n",
      "0      IVI-OB6     Dam Dispenser  Dam dispenser #1      AJX75334501   \n",
      "1      IVI-OB6     Dam Dispenser  Dam dispenser #2      AJX75334501   \n",
      "2      IVI-OB6     Dam Dispenser  Dam dispenser #1      AJX75334501   \n",
      "3      IVI-OB6     Dam Dispenser  Dam dispenser #2      AJX75334501   \n",
      "4      IVI-OB6     Dam Dispenser  Dam dispenser #1      AJX75334501   \n",
      "\n",
      "  Workorder_Dam  Insp. Seq No._Dam Insp Judge Code_Dam  \\\n",
      "0    3G1XB278-1                  1                  OK   \n",
      "1    3I1XB274-1                  1                  OK   \n",
      "2    3G1X8298-1                  1                  OK   \n",
      "3    4B1X9671-2                  1                  OK   \n",
      "4    3J1XC129-1                  1                  OK   \n",
      "\n",
      "   CURE END POSITION X Collect Result_Dam  CURE END POSITION X Unit Time_Dam  \\\n",
      "0                                   240.0                                NaN   \n",
      "1                                  1000.0                                NaN   \n",
      "2                                   240.0                                NaN   \n",
      "3                                  1000.0                                NaN   \n",
      "4                                   240.0                                NaN   \n",
      "\n",
      "   CURE END POSITION X Judge Value_Dam  ...  Production Qty Judge Value_Fill2  \\\n",
      "0                                  NaN  ...                               NaN   \n",
      "1                                  NaN  ...                               NaN   \n",
      "2                                  NaN  ...                               NaN   \n",
      "3                                  NaN  ...                               NaN   \n",
      "4                                  NaN  ...                               NaN   \n",
      "\n",
      "   Receip No Collect Result_Fill2  Receip No Unit Time_Fill2  \\\n",
      "0                               1                        NaN   \n",
      "1                               1                        NaN   \n",
      "2                               1                        NaN   \n",
      "3                               1                        NaN   \n",
      "4                               1                        NaN   \n",
      "\n",
      "   Receip No Judge Value_Fill2  WorkMode Collect Result_Fill2  \\\n",
      "0                          NaN                              0   \n",
      "1                          NaN                              0   \n",
      "2                          NaN                              0   \n",
      "3                          NaN                              0   \n",
      "4                          NaN                              0   \n",
      "\n",
      "   WorkMode Unit Time_Fill2  WorkMode Judge Value_Fill2  target  \\\n",
      "0                       NaN                         NaN  Normal   \n",
      "1                       NaN                         NaN  Normal   \n",
      "2                       NaN                         NaN  Normal   \n",
      "3                       NaN                         NaN  Normal   \n",
      "4                       NaN                         NaN  Normal   \n",
      "\n",
      "   target_numeric  Workorder_Fill2_Target_Encoded_CV  \n",
      "0               0                           0.818182  \n",
      "1               0                           0.250000  \n",
      "2               0                           0.562500  \n",
      "3               0                           0.400000  \n",
      "4               0                           0.750000  \n",
      "\n",
      "[5 rows x 466 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV 파일을 불러와서 df_concat이라는 DataFrame으로 저장\n",
    "df = pd.read_csv('new_df_concat.csv')\n",
    "\n",
    "# 불러온 데이터 확인 (옵션)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67eda68-f2d9-4612-a682-b448c5310b21",
   "metadata": {},
   "source": [
    "### train 예측값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a2baf8-5f91-4277-b468-ca1f9d73f9b4",
   "metadata": {},
   "source": [
    "## train 돌리고 y_pred 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "063fe24a-670e-40c7-9b5a-defedc281d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.65      0.64      2350\n",
      "           1       0.64      0.61      0.62      2350\n",
      "\n",
      "    accuracy                           0.63      4700\n",
      "   macro avg       0.63      0.63      0.63      4700\n",
      "weighted avg       0.63      0.63      0.63      4700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "# 사용할 변수들\n",
    "selected_features = [\n",
    "    'Workorder_Fill2_Target_Encoded_CV', 'Production Qty Collect Result_Fill2', \n",
    "    'Production Qty Collect Result_Dam', 'Production Qty Collect Result_Fill1', \n",
    "    '1st Pressure Collect Result_AutoClave', 'Machine Tact time Collect Result_Fill2',\n",
    "    'Machine Tact time Collect Result_Fill1', 'Machine Tact time Collect Result_Dam',\n",
    "    'Chamber Temp. Collect Result_AutoClave', '2nd Pressure Collect Result_AutoClave', \n",
    "    '3rd Pressure Collect Result_AutoClave', 'PalletID Collect Result_Fill2', \n",
    "    'PalletID Collect Result_Fill1', 'PalletID Collect Result_Dam', \n",
    "    'Dispense Volume(Stage2) Collect Result_Dam', \n",
    "    'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam', \n",
    "    'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam', \n",
    "    'Dispense Volume(Stage1) Collect Result_Fill1', \n",
    "    'Dispense Volume(Stage3) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1', \n",
    "    'Dispense Volume(Stage2) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam', \n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1', \n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1', \n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1', \n",
    "    'Dispense Volume(Stage3) Collect Result_Dam'\n",
    "]\n",
    "\n",
    "# 데이터 전처리\n",
    "X = df[selected_features].fillna(0)\n",
    "y = df['target_numeric']\n",
    "\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 최적의 하이퍼파라미터를 사용한 랜덤 포레스트 및 그레디언트 부스팅 모델\n",
    "best_rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=None,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "best_gb = GradientBoostingClassifier(\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=100,\n",
    "    max_depth=7,\n",
    "    subsample=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 스태킹 모델 구성\n",
    "base_models = [\n",
    "    ('rf', best_rf),\n",
    "    ('gb', best_gb)\n",
    "]\n",
    "\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_model,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# 모델 학습 및 예측\n",
    "y_pred = cross_val_predict(stacking_model, X_scaled, y, cv=5)\n",
    "\n",
    "# 평가 지표 계산 및 출력\n",
    "report = classification_report(y, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df86c5c1-14ea-4d02-9ed3-d7d3b2ce146d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe14d02-e0a9-4660-bada-b775f3ddc8b4",
   "metadata": {},
   "source": [
    "### test data 예측값\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09bd03cd-2c49-43fd-94d7-04beee7f060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Train 데이터 불러오기 및 전처리\n",
    "train_df = pd.read_csv('new_df_concat.csv')\n",
    "test_df = pd.read_csv('correct_test_data.csv')\n",
    "\n",
    "# 사용할 변수들\n",
    "selected_features = [\n",
    "    'Workorder_Fill2_Target_Encoded_CV', 'Production Qty Collect Result_Fill2', \n",
    "    'Production Qty Collect Result_Dam', 'Production Qty Collect Result_Fill1', \n",
    "    '1st Pressure Collect Result_AutoClave', 'Machine Tact time Collect Result_Fill2',\n",
    "    'Machine Tact time Collect Result_Fill1', 'Machine Tact time Collect Result_Dam',\n",
    "    'Chamber Temp. Collect Result_AutoClave', '2nd Pressure Collect Result_AutoClave', \n",
    "    '3rd Pressure Collect Result_AutoClave', 'PalletID Collect Result_Fill2', \n",
    "    'PalletID Collect Result_Fill1', 'PalletID Collect Result_Dam', \n",
    "    'Dispense Volume(Stage2) Collect Result_Dam', \n",
    "    'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam', \n",
    "    'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam', \n",
    "    'Dispense Volume(Stage1) Collect Result_Fill1', \n",
    "    'Dispense Volume(Stage3) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1', \n",
    "    'Dispense Volume(Stage2) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam', \n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1', \n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1', \n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1', \n",
    "    'Dispense Volume(Stage3) Collect Result_Dam'\n",
    "]\n",
    "\n",
    "# Train 데이터에서 피처와 타겟 변수 선택\n",
    "X_train = train_df[selected_features].fillna(0)\n",
    "y_train = train_df['target_numeric']  # 실제 타겟 컬럼으로 변경해야 함\n",
    "\n",
    "# Test 데이터에서 피처 선택\n",
    "X_test = test_df[selected_features].fillna(0)\n",
    "\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 최적의 하이퍼파라미터를 사용한 랜덤 포레스트 및 그레디언트 부스팅 모델\n",
    "best_rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=None,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "best_gb = GradientBoostingClassifier(\n",
    "    learning_rate=0.01,\n",
    "    n_estimators=100,\n",
    "    max_depth=7,\n",
    "    subsample=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 스태킹 모델 구성\n",
    "base_models = [\n",
    "    ('rf', best_rf),\n",
    "    ('gb', best_gb)\n",
    "]\n",
    "\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_model,\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "stacking_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Test 데이터를 사용하여 타겟 변수 예측\n",
    "y_pred = stacking_model.predict(X_test_scaled)\n",
    "\n",
    "# 예측 결과를 Test 데이터프레임에 추가\n",
    "test_df['predicted_target'] = y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "151b89d9-4a66-48d1-bbf0-ce8d4775c685",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = test_df['predicted_target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b541728-5abd-4f5f-8613-ed11429d02e3",
   "metadata": {},
   "source": [
    "### 평가지표함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3066a35-33d1-4bc5-943d-a7cf79bb1bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_class_distribution(y_pred):\n",
    "    \"\"\"\n",
    "    예측된 클래스의 개수와 비율을 분석하고, 평균 및 중간값을 계산하는 함수\n",
    "\n",
    "    Parameters:\n",
    "    y_pred (array-like): 예측된 클래스 레이블\n",
    "\n",
    "    Returns:\n",
    "    dict: 클래스별 개수, 비율, 비율의 평균 및 중간값\n",
    "    \"\"\"\n",
    "    # 예측된 클래스의 유니크 값과 해당 값들의 개수 계산\n",
    "    unique_classes, counts = np.unique(y_pred, return_counts=True)\n",
    "\n",
    "    # 클래스별 개수 및 비율 계산\n",
    "    total_count = len(y_pred)\n",
    "    class_counts = dict(zip(unique_classes, counts))\n",
    "    class_ratios = {cls: count / total_count for cls, count in class_counts.items()}\n",
    "\n",
    "    # 결과를 딕셔너리로 반환\n",
    "    results = {\n",
    "        'class_counts': class_counts,\n",
    "        'class_ratios': class_ratios\n",
    "    }\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bed2515f-4916-43cc-a981-936fd099bd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스별 개수: {0: 2461, 1: 2239}\n",
      "클래스별 비율: {0: 0.5236170212765957, 1: 0.47638297872340424}\n"
     ]
    }
   ],
   "source": [
    "analysis = analyze_class_distribution(y_pred)\n",
    "\n",
    "print(\"클래스별 개수:\", analysis['class_counts'])\n",
    "print(\"클래스별 비율:\", analysis['class_ratios'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4dd1f99-ee03-4638-ba84-70d9ede9df6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스별 개수: {'AbNormal': 2350, 'Normal': 2350}\n",
      "클래스별 비율: {'AbNormal': 0.5, 'Normal': 0.5}\n"
     ]
    }
   ],
   "source": [
    "analysis = analyze_class_distribution(y_valid)\n",
    "\n",
    "print(\"클래스별 개수:\", analysis['class_counts'])\n",
    "print(\"클래스별 비율:\", analysis['class_ratios'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5edc58f-217d-41b2-87e6-bf69aa9df415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스별 개수: {0: 11249, 1: 6112}\n",
      "클래스별 비율: {0: 0.6479465468578999, 1: 0.3520534531421001}\n"
     ]
    }
   ],
   "source": [
    "analysis = analyze_class_distribution(y_test_pred)\n",
    "\n",
    "print(\"클래스별 개수:\", analysis['class_counts'])\n",
    "print(\"클래스별 비율:\", analysis['class_ratios'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffb9ab3-c8e4-4017-a922-514281a3bd96",
   "metadata": {},
   "source": [
    "# EasyEnsembleClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b559ed5-5ced-4b35-9918-6260605c53ab",
   "metadata": {},
   "source": [
    "### train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b365764-9c1f-4587-8341-12333f42bbcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.65      0.62      2350\n",
      "           1       0.61      0.55      0.58      2350\n",
      "\n",
      "    accuracy                           0.60      4700\n",
      "   macro avg       0.60      0.60      0.60      4700\n",
      "weighted avg       0.60      0.60      0.60      4700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 데이터 전처리\n",
    "X = df[selected_features].fillna(0)\n",
    "y = df['target_numeric']\n",
    "\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# EasyEnsembleClassifier 설정\n",
    "eec = EasyEnsembleClassifier(\n",
    "    n_estimators=10,  # 앙상블에 포함될 학습기 수\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 모델 학습 및 예측\n",
    "y_pred_eec = cross_val_predict(eec, X_scaled, y, cv=5)\n",
    "\n",
    "# 평가 지표 계산 및 출력\n",
    "report_eec = classification_report(y, y_pred_eec)\n",
    "print(report_eec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c120dca-5294-4c4f-9a7a-5b6674cfce86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스별 개수: {0: 2592, 1: 2108}\n",
      "클래스별 비율: {0: 0.5514893617021277, 1: 0.44851063829787235}\n"
     ]
    }
   ],
   "source": [
    "analysis = analyze_class_distribution(y_pred_eec)\n",
    "\n",
    "print(\"클래스별 개수:\", analysis['class_counts'])\n",
    "print(\"클래스별 비율:\", analysis['class_ratios'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8fc85829-dce3-4646-83f4-7801efa409a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스별 개수: {'AbNormal': 2350, 'Normal': 2350}\n",
      "클래스별 비율: {'AbNormal': 0.5, 'Normal': 0.5}\n"
     ]
    }
   ],
   "source": [
    "analysis = analyze_class_distribution(y_valid)\n",
    "\n",
    "print(\"클래스별 개수:\", analysis['class_counts'])\n",
    "print(\"클래스별 비율:\", analysis['class_ratios'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242c9c3b-0db1-4ef9-b94c-1e5586363c64",
   "metadata": {},
   "source": [
    "### test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b8002e6-71f1-4631-8a6a-7c304b16023b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   predicted_target\n",
      "0                 1\n",
      "1                 0\n",
      "2                 1\n",
      "3                 1\n",
      "4                 0\n"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Train 데이터와 Test 데이터 불러오기\n",
    "train_df = pd.read_csv('new_df_concat.csv')\n",
    "test_df = pd.read_csv('correct_test_data.csv')\n",
    "\n",
    "# 사용할 변수들\n",
    "selected_features = [\n",
    "    'Workorder_Fill2_Target_Encoded_CV', 'Production Qty Collect Result_Fill2', \n",
    "    'Production Qty Collect Result_Dam', 'Production Qty Collect Result_Fill1', \n",
    "    '1st Pressure Collect Result_AutoClave', 'Machine Tact time Collect Result_Fill2',\n",
    "    'Machine Tact time Collect Result_Fill1', 'Machine Tact time Collect Result_Dam',\n",
    "    'Chamber Temp. Collect Result_AutoClave', '2nd Pressure Collect Result_AutoClave', \n",
    "    '3rd Pressure Collect Result_AutoClave', 'PalletID Collect Result_Fill2', \n",
    "    'PalletID Collect Result_Fill1', 'PalletID Collect Result_Dam', \n",
    "    'Dispense Volume(Stage2) Collect Result_Dam', \n",
    "    'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam', \n",
    "    'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam', \n",
    "    'Dispense Volume(Stage1) Collect Result_Fill1', \n",
    "    'Dispense Volume(Stage3) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1', \n",
    "    'Dispense Volume(Stage2) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam', \n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1', \n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1', \n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1', \n",
    "    'Dispense Volume(Stage3) Collect Result_Dam'\n",
    "]\n",
    "\n",
    "# Train 데이터에서 피처와 타겟 변수 선택\n",
    "X_train = train_df[selected_features].fillna(0)\n",
    "y_train = train_df['target_numeric']  # 타겟 변수\n",
    "\n",
    "# Test 데이터에서 피처 선택\n",
    "X_test = test_df[selected_features].fillna(0)\n",
    "\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# EasyEnsembleClassifier 설정\n",
    "eec = EasyEnsembleClassifier(\n",
    "    n_estimators=10,  # 앙상블에 포함될 학습기 수\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "eec.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Test 데이터를 사용하여 타겟 변수 예측\n",
    "y_pred_test = eec.predict(X_test_scaled)\n",
    "\n",
    "# 예측 결과를 Test 데이터프레임에 추가\n",
    "test_df['predicted_target'] = y_pred_test\n",
    "\n",
    "# 예측 결과 확인\n",
    "print(test_df[['predicted_target']].head())\n",
    "\n",
    "# 필요 시 예측 결과를 CSV 파일로 저장\n",
    "# test_df.to_csv('predicted_test_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68438ae4-1d5d-4ee4-b1c5-d2a46b939a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = test_df['predicted_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "11189b4e-ed1d-492b-882c-d370078e70a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스별 개수: {0: 12728, 1: 4633}\n",
      "클래스별 비율: {0: 0.7331374920799493, 1: 0.2668625079200507}\n"
     ]
    }
   ],
   "source": [
    "analysis = analyze_class_distribution(y_test_pred)\n",
    "\n",
    "print(\"클래스별 개수:\", analysis['class_counts'])\n",
    "print(\"클래스별 비율:\", analysis['class_ratios'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d5684a-48ca-4a01-9000-7b00b1a3c59d",
   "metadata": {},
   "source": [
    "# RUSBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c97864-5988-4270-9126-d015e4ccf073",
   "metadata": {},
   "source": [
    "### train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02ec4bfc-694d-40fe-aa90-892df60d8ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.63      0.61      2350\n",
      "           1       0.61      0.57      0.59      2350\n",
      "\n",
      "    accuracy                           0.60      4700\n",
      "   macro avg       0.60      0.60      0.60      4700\n",
      "weighted avg       0.60      0.60      0.60      4700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 사용할 변수들\n",
    "selected_features = [\n",
    "    'Workorder_Fill2_Target_Encoded_CV', 'Production Qty Collect Result_Fill2', \n",
    "    'Production Qty Collect Result_Dam', 'Production Qty Collect Result_Fill1', \n",
    "    '1st Pressure Collect Result_AutoClave', 'Machine Tact time Collect Result_Fill2',\n",
    "    'Machine Tact time Collect Result_Fill1', 'Machine Tact time Collect Result_Dam',\n",
    "    'Chamber Temp. Collect Result_AutoClave', '2nd Pressure Collect Result_AutoClave', \n",
    "    '3rd Pressure Collect Result_AutoClave', 'PalletID Collect Result_Fill2', \n",
    "    'PalletID Collect Result_Fill1', 'PalletID Collect Result_Dam', \n",
    "    'Dispense Volume(Stage2) Collect Result_Dam', \n",
    "    'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam', \n",
    "    'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam', \n",
    "    'Dispense Volume(Stage1) Collect Result_Fill1', \n",
    "    'Dispense Volume(Stage3) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1', \n",
    "    'Dispense Volume(Stage2) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam', \n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1', \n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1', \n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1', \n",
    "    'Dispense Volume(Stage3) Collect Result_Dam'\n",
    "]\n",
    "\n",
    "# 데이터 전처리\n",
    "X = df[selected_features].fillna(0)\n",
    "y = df['target_numeric']\n",
    "\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# RUSBoostClassifier 설정\n",
    "rusboost = RUSBoostClassifier(\n",
    "    n_estimators=50,  # 기본 부스팅 단계 수\n",
    "    learning_rate=1.0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 모델 학습 및 예측\n",
    "y_pred_rusboost = cross_val_predict(rusboost, X_scaled, y, cv=5)\n",
    "\n",
    "# 평가 지표 계산 및 출력\n",
    "report_rusboost = classification_report(y, y_pred_rusboost)\n",
    "print(report_rusboost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "662c251b-9592-4a3b-97d5-84750c4d7f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스별 개수: {0: 2486, 1: 2214}\n",
      "클래스별 비율: {0: 0.528936170212766, 1: 0.47106382978723405}\n"
     ]
    }
   ],
   "source": [
    "analysis = analyze_class_distribution(y_pred_rusboost)\n",
    "\n",
    "print(\"클래스별 개수:\", analysis['class_counts'])\n",
    "print(\"클래스별 비율:\", analysis['class_ratios'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a71402b-7bff-4192-ad72-2b2d9ac4589f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스별 개수: {'AbNormal': 2350, 'Normal': 2350}\n",
      "클래스별 비율: {'AbNormal': 0.5, 'Normal': 0.5}\n"
     ]
    }
   ],
   "source": [
    "analysis = analyze_class_distribution(y_valid)\n",
    "\n",
    "print(\"클래스별 개수:\", analysis['class_counts'])\n",
    "print(\"클래스별 비율:\", analysis['class_ratios'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20960de2-e397-4318-a216-b7cc47e9a297",
   "metadata": {},
   "source": [
    "### test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4e55adf4-9e88-4380-bbf3-1a291caf26b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   predicted_target\n",
      "0                 1\n",
      "1                 0\n",
      "2                 1\n",
      "3                 1\n",
      "4                 0\n"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Train 데이터와 Test 데이터 불러오기\n",
    "train_df = pd.read_csv('new_df_concat.csv')\n",
    "test_df = pd.read_csv('correct_test_data.csv')\n",
    "\n",
    "# 사용할 변수들\n",
    "selected_features = [\n",
    "    'Workorder_Fill2_Target_Encoded_CV', 'Production Qty Collect Result_Fill2', \n",
    "    'Production Qty Collect Result_Dam', 'Production Qty Collect Result_Fill1', \n",
    "    '1st Pressure Collect Result_AutoClave', 'Machine Tact time Collect Result_Fill2',\n",
    "    'Machine Tact time Collect Result_Fill1', 'Machine Tact time Collect Result_Dam',\n",
    "    'Chamber Temp. Collect Result_AutoClave', '2nd Pressure Collect Result_AutoClave', \n",
    "    '3rd Pressure Collect Result_AutoClave', 'PalletID Collect Result_Fill2', \n",
    "    'PalletID Collect Result_Fill1', 'PalletID Collect Result_Dam', \n",
    "    'Dispense Volume(Stage2) Collect Result_Dam', \n",
    "    'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam', \n",
    "    'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam', \n",
    "    'Dispense Volume(Stage1) Collect Result_Fill1', \n",
    "    'Dispense Volume(Stage3) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1', \n",
    "    'Dispense Volume(Stage2) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam', \n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1', \n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1', \n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1', \n",
    "    'Dispense Volume(Stage3) Collect Result_Dam'\n",
    "]\n",
    "\n",
    "# Train 데이터에서 피처와 타겟 변수 선택\n",
    "X_train = train_df[selected_features].fillna(0)\n",
    "y_train = train_df['target_numeric']  # 타겟 변수\n",
    "\n",
    "# Test 데이터에서 피처 선택\n",
    "X_test = test_df[selected_features].fillna(0)\n",
    "\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# RUSBoostClassifier 설정\n",
    "rusboost = RUSBoostClassifier(\n",
    "    n_estimators=50,  # 기본 부스팅 단계 수\n",
    "    learning_rate=1.0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "rusboost.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Test 데이터를 사용하여 타겟 변수 예측\n",
    "y_pred_test = rusboost.predict(X_test_scaled)\n",
    "\n",
    "# 예측 결과를 Test 데이터프레임에 추가\n",
    "test_df['predicted_target'] = y_pred_test\n",
    "\n",
    "# 예측 결과 확인\n",
    "print(test_df[['predicted_target']].head())\n",
    "\n",
    "# 필요 시 예측 결과를 CSV 파일로 저장\n",
    "# test_df.to_csv('predicted_test_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da5801b6-dccf-4412-be2e-1f1fbda9cc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = test_df['predicted_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "faf38e5c-c029-4164-8d6b-30c2e0f0f164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스별 개수: {0: 11815, 1: 5546}\n",
      "클래스별 비율: {0: 0.6805483555094752, 1: 0.31945164449052477}\n"
     ]
    }
   ],
   "source": [
    "analysis = analyze_class_distribution(y_test_pred)\n",
    "\n",
    "print(\"클래스별 개수:\", analysis['class_counts'])\n",
    "print(\"클래스별 비율:\", analysis['class_ratios'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1105a0a2-d71f-456d-be14-57249b42120a",
   "metadata": {},
   "source": [
    "# BalancedBaggingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8ca9ff-cfec-49e9-98bf-d4e7dded89a2",
   "metadata": {},
   "source": [
    "### traindata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bebfdc26-df68-41f8-af7b-c2713d3d4730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.66      0.64      2350\n",
      "           1       0.63      0.58      0.61      2350\n",
      "\n",
      "    accuracy                           0.62      4700\n",
      "   macro avg       0.62      0.62      0.62      4700\n",
      "weighted avg       0.62      0.62      0.62      4700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 사용할 변수들\n",
    "selected_features = [\n",
    "    'Workorder_Fill2_Target_Encoded_CV', 'Production Qty Collect Result_Fill2', \n",
    "    'Production Qty Collect Result_Dam', 'Production Qty Collect Result_Fill1', \n",
    "    '1st Pressure Collect Result_AutoClave', 'Machine Tact time Collect Result_Fill2',\n",
    "    'Machine Tact time Collect Result_Fill1', 'Machine Tact time Collect Result_Dam',\n",
    "    'Chamber Temp. Collect Result_AutoClave', '2nd Pressure Collect Result_AutoClave', \n",
    "    '3rd Pressure Collect Result_AutoClave', 'PalletID Collect Result_Fill2', \n",
    "    'PalletID Collect Result_Fill1', 'PalletID Collect Result_Dam', \n",
    "    'Dispense Volume(Stage2) Collect Result_Dam', \n",
    "    'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam', \n",
    "    'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam', \n",
    "    'Dispense Volume(Stage1) Collect Result_Fill1', \n",
    "    'Dispense Volume(Stage3) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1', \n",
    "    'Dispense Volume(Stage2) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam', \n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1', \n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1', \n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1', \n",
    "    'Dispense Volume(Stage3) Collect Result_Dam'\n",
    "]\n",
    "\n",
    "# 데이터 전처리\n",
    "X = df[selected_features].fillna(0)\n",
    "y = df['target_numeric']\n",
    "\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# BalancedBaggingClassifier 설정\n",
    "balanced_bagging = BalancedBaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(),  # 기본 학습기로 결정 트리 사용\n",
    "    n_estimators=50,  # 앙상블에 포함될 학습기 수\n",
    "    sampling_strategy='auto',  # 자동 균형 잡힌 샘플링\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 모델 학습 및 예측\n",
    "y_pred_balanced_bagging = cross_val_predict(balanced_bagging, X_scaled, y, cv=5)\n",
    "\n",
    "# 평가 지표 계산 및 출력\n",
    "report_balanced_bagging = classification_report(y, y_pred_balanced_bagging)\n",
    "print(report_balanced_bagging)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "16864359-4737-4d3a-b8d0-c01b1f537c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스별 개수: {0: 2543, 1: 2157}\n",
      "클래스별 비율: {0: 0.541063829787234, 1: 0.45893617021276595}\n"
     ]
    }
   ],
   "source": [
    "analysis = analyze_class_distribution(y_pred_balanced_bagging)\n",
    "\n",
    "print(\"클래스별 개수:\", analysis['class_counts'])\n",
    "print(\"클래스별 비율:\", analysis['class_ratios'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d1cc847e-d25b-45f2-a253-8e7b16e55492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스별 개수: {'AbNormal': 2350, 'Normal': 2350}\n",
      "클래스별 비율: {'AbNormal': 0.5, 'Normal': 0.5}\n"
     ]
    }
   ],
   "source": [
    "analysis = analyze_class_distribution(y_valid)\n",
    "\n",
    "print(\"클래스별 개수:\", analysis['class_counts'])\n",
    "print(\"클래스별 비율:\", analysis['class_ratios'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4ed45c-48d6-44a3-9e7e-bbf45e7eafe4",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cdaed618-c84e-4379-a4f9-2337828f3cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   predicted_target\n",
      "0                 1\n",
      "1                 0\n",
      "2                 0\n",
      "3                 1\n",
      "4                 0\n"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Train 데이터와 Test 데이터 불러오기\n",
    "train_df = pd.read_csv('new_df_concat.csv')\n",
    "test_df = pd.read_csv('correct_test_data.csv')\n",
    "\n",
    "# 사용할 변수들\n",
    "selected_features = [\n",
    "    'Workorder_Fill2_Target_Encoded_CV', 'Production Qty Collect Result_Fill2', \n",
    "    'Production Qty Collect Result_Dam', 'Production Qty Collect Result_Fill1', \n",
    "    '1st Pressure Collect Result_AutoClave', 'Machine Tact time Collect Result_Fill2',\n",
    "    'Machine Tact time Collect Result_Fill1', 'Machine Tact time Collect Result_Dam',\n",
    "    'Chamber Temp. Collect Result_AutoClave', '2nd Pressure Collect Result_AutoClave', \n",
    "    '3rd Pressure Collect Result_AutoClave', 'PalletID Collect Result_Fill2', \n",
    "    'PalletID Collect Result_Fill1', 'PalletID Collect Result_Dam', \n",
    "    'Dispense Volume(Stage2) Collect Result_Dam', \n",
    "    'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam', \n",
    "    'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam', \n",
    "    'Dispense Volume(Stage1) Collect Result_Fill1', \n",
    "    'Dispense Volume(Stage3) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1', \n",
    "    'Dispense Volume(Stage2) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam', \n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1', \n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1', \n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1', \n",
    "    'Dispense Volume(Stage3) Collect Result_Dam'\n",
    "]\n",
    "\n",
    "# Train 데이터에서 피처와 타겟 변수 선택\n",
    "X_train = train_df[selected_features].fillna(0)\n",
    "y_train = train_df['target_numeric']  # 타겟 변수\n",
    "\n",
    "# Test 데이터에서 피처 선택\n",
    "X_test = test_df[selected_features].fillna(0)\n",
    "\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# BalancedBaggingClassifier 설정\n",
    "balanced_bagging = BalancedBaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(),  # 기본 학습기로 결정 트리 사용\n",
    "    n_estimators=50,  # 앙상블에 포함될 학습기 수\n",
    "    sampling_strategy='auto',  # 자동 균형 잡힌 샘플링\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "balanced_bagging.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Test 데이터를 사용하여 타겟 변수 예측\n",
    "y_pred_test = balanced_bagging.predict(X_test_scaled)\n",
    "\n",
    "# 예측 결과를 Test 데이터프레임에 추가\n",
    "test_df['predicted_target'] = y_pred_test\n",
    "\n",
    "# 예측 결과 확인\n",
    "print(test_df[['predicted_target']].head())\n",
    "\n",
    "# 필요 시 예측 결과를 CSV 파일로 저장\n",
    "# test_df.to_csv('predicted_test_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bb020a9e-483f-4af1-a6db-e0df0850c365",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = test_df['predicted_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a41e21a6-f849-4b35-b1e8-4dc4911ccb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스별 개수: {0: 10821, 1: 6540}\n",
      "클래스별 비율: {0: 0.6232935890789701, 1: 0.3767064109210299}\n"
     ]
    }
   ],
   "source": [
    "analysis = analyze_class_distribution(y_test_pred)\n",
    "\n",
    "print(\"클래스별 개수:\", analysis['class_counts'])\n",
    "print(\"클래스별 비율:\", analysis['class_ratios'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687bed4e-152b-47dc-a9b4-b374d69b8821",
   "metadata": {},
   "source": [
    "# BalancedRandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ad1c28-8f68-4797-95b1-f74a2a145b71",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a5e7a716-6220-4b7d-9e68-ae263805a4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lee seung woo\\AppData\\Roaming\\Python\\Python311\\site-packages\\imblearn\\ensemble\\_forest.py:577: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "C:\\Users\\lee seung woo\\AppData\\Roaming\\Python\\Python311\\site-packages\\imblearn\\ensemble\\_forest.py:589: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "C:\\Users\\lee seung woo\\AppData\\Roaming\\Python\\Python311\\site-packages\\imblearn\\ensemble\\_forest.py:601: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "C:\\Users\\lee seung woo\\AppData\\Roaming\\Python\\Python311\\site-packages\\imblearn\\ensemble\\_forest.py:577: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "C:\\Users\\lee seung woo\\AppData\\Roaming\\Python\\Python311\\site-packages\\imblearn\\ensemble\\_forest.py:589: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "C:\\Users\\lee seung woo\\AppData\\Roaming\\Python\\Python311\\site-packages\\imblearn\\ensemble\\_forest.py:601: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "C:\\Users\\lee seung woo\\AppData\\Roaming\\Python\\Python311\\site-packages\\imblearn\\ensemble\\_forest.py:577: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "C:\\Users\\lee seung woo\\AppData\\Roaming\\Python\\Python311\\site-packages\\imblearn\\ensemble\\_forest.py:589: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "C:\\Users\\lee seung woo\\AppData\\Roaming\\Python\\Python311\\site-packages\\imblearn\\ensemble\\_forest.py:601: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "C:\\Users\\lee seung woo\\AppData\\Roaming\\Python\\Python311\\site-packages\\imblearn\\ensemble\\_forest.py:577: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "C:\\Users\\lee seung woo\\AppData\\Roaming\\Python\\Python311\\site-packages\\imblearn\\ensemble\\_forest.py:589: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "C:\\Users\\lee seung woo\\AppData\\Roaming\\Python\\Python311\\site-packages\\imblearn\\ensemble\\_forest.py:601: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "C:\\Users\\lee seung woo\\AppData\\Roaming\\Python\\Python311\\site-packages\\imblearn\\ensemble\\_forest.py:577: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "C:\\Users\\lee seung woo\\AppData\\Roaming\\Python\\Python311\\site-packages\\imblearn\\ensemble\\_forest.py:589: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "C:\\Users\\lee seung woo\\AppData\\Roaming\\Python\\Python311\\site-packages\\imblearn\\ensemble\\_forest.py:601: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.65      0.64      2350\n",
      "           1       0.63      0.60      0.62      2350\n",
      "\n",
      "    accuracy                           0.63      4700\n",
      "   macro avg       0.63      0.63      0.63      4700\n",
      "weighted avg       0.63      0.63      0.63      4700\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 사용할 변수들\n",
    "selected_features = [\n",
    "    'Workorder_Fill2_Target_Encoded_CV', 'Production Qty Collect Result_Fill2', \n",
    "    'Production Qty Collect Result_Dam', 'Production Qty Collect Result_Fill1', \n",
    "    '1st Pressure Collect Result_AutoClave', 'Machine Tact time Collect Result_Fill2',\n",
    "    'Machine Tact time Collect Result_Fill1', 'Machine Tact time Collect Result_Dam',\n",
    "    'Chamber Temp. Collect Result_AutoClave', '2nd Pressure Collect Result_AutoClave', \n",
    "    '3rd Pressure Collect Result_AutoClave', 'PalletID Collect Result_Fill2', \n",
    "    'PalletID Collect Result_Fill1', 'PalletID Collect Result_Dam', \n",
    "    'Dispense Volume(Stage2) Collect Result_Dam', \n",
    "    'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam', \n",
    "    'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam', \n",
    "    'Dispense Volume(Stage1) Collect Result_Fill1', \n",
    "    'Dispense Volume(Stage3) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1', \n",
    "    'Dispense Volume(Stage2) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam', \n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1', \n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1', \n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1', \n",
    "    'Dispense Volume(Stage3) Collect Result_Dam'\n",
    "]\n",
    "\n",
    "# 데이터 전처리\n",
    "X = df[selected_features].fillna(0)\n",
    "y = df['target_numeric']\n",
    "\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# BalancedRandomForestClassifier 설정\n",
    "balanced_rf = BalancedRandomForestClassifier(\n",
    "    n_estimators=100,  # 기본 트리 수\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 모델 학습 및 예측\n",
    "y_pred_balanced_rf = cross_val_predict(balanced_rf, X_scaled, y, cv=5)\n",
    "\n",
    "# 평가 지표 계산 및 출력\n",
    "report_balanced_rf = classification_report(y, y_pred_balanced_rf)\n",
    "print(report_balanced_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "88549104-7ceb-443a-82e4-873f0b6b2115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스별 개수: {0: 2476, 1: 2224}\n",
      "클래스별 비율: {0: 0.5268085106382979, 1: 0.47319148936170213}\n"
     ]
    }
   ],
   "source": [
    "analysis = analyze_class_distribution(y_pred_balanced_rf)\n",
    "\n",
    "print(\"클래스별 개수:\", analysis['class_counts'])\n",
    "print(\"클래스별 비율:\", analysis['class_ratios'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9813ac41-eb10-4384-856c-f4721a27e6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스별 개수: {'AbNormal': 2350, 'Normal': 2350}\n",
      "클래스별 비율: {'AbNormal': 0.5, 'Normal': 0.5}\n"
     ]
    }
   ],
   "source": [
    "analysis = analyze_class_distribution(y_valid)\n",
    "\n",
    "print(\"클래스별 개수:\", analysis['class_counts'])\n",
    "print(\"클래스별 비율:\", analysis['class_ratios'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce334cd5-4fd1-4484-b4ff-dec56e2ace4a",
   "metadata": {},
   "source": [
    "### test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "628e1ed7-3448-4a92-baeb-88fa98e45bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lee seung woo\\AppData\\Roaming\\Python\\Python311\\site-packages\\imblearn\\ensemble\\_forest.py:577: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "C:\\Users\\lee seung woo\\AppData\\Roaming\\Python\\Python311\\site-packages\\imblearn\\ensemble\\_forest.py:589: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "C:\\Users\\lee seung woo\\AppData\\Roaming\\Python\\Python311\\site-packages\\imblearn\\ensemble\\_forest.py:601: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   predicted_target\n",
      "0                 1\n",
      "1                 0\n",
      "2                 1\n",
      "3                 1\n",
      "4                 0\n"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Train 데이터와 Test 데이터 불러오기\n",
    "train_df = pd.read_csv('new_df_concat.csv')\n",
    "test_df = pd.read_csv('correct_test_data.csv')\n",
    "\n",
    "# 사용할 변수들\n",
    "selected_features = [\n",
    "    'Workorder_Fill2_Target_Encoded_CV', 'Production Qty Collect Result_Fill2', \n",
    "    'Production Qty Collect Result_Dam', 'Production Qty Collect Result_Fill1', \n",
    "    '1st Pressure Collect Result_AutoClave', 'Machine Tact time Collect Result_Fill2',\n",
    "    'Machine Tact time Collect Result_Fill1', 'Machine Tact time Collect Result_Dam',\n",
    "    'Chamber Temp. Collect Result_AutoClave', '2nd Pressure Collect Result_AutoClave', \n",
    "    '3rd Pressure Collect Result_AutoClave', 'PalletID Collect Result_Fill2', \n",
    "    'PalletID Collect Result_Fill1', 'PalletID Collect Result_Dam', \n",
    "    'Dispense Volume(Stage2) Collect Result_Dam', \n",
    "    'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Dam', \n",
    "    'DISCHARGED TIME OF RESIN(Stage2) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Dam', \n",
    "    'Dispense Volume(Stage1) Collect Result_Fill1', \n",
    "    'Dispense Volume(Stage3) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Fill1', \n",
    "    'Dispense Volume(Stage2) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage3) Collect Result_Dam', \n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage2) Collect Result_Fill1', \n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage3) Collect Result_Fill1', \n",
    "    'DISCHARGED TIME OF RESIN(Stage1) Collect Result_Fill1', \n",
    "    'HEAD NORMAL COORDINATE X AXIS(Stage1) Collect Result_Fill1', \n",
    "    'Dispense Volume(Stage3) Collect Result_Dam'\n",
    "]\n",
    "\n",
    "# Train 데이터에서 피처와 타겟 변수 선택\n",
    "X_train = train_df[selected_features].fillna(0)\n",
    "y_train = train_df['target_numeric']  # 타겟 변수\n",
    "\n",
    "# Test 데이터에서 피처 선택\n",
    "X_test = test_df[selected_features].fillna(0)\n",
    "\n",
    "# 스케일링\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# BalancedRandomForestClassifier 설정\n",
    "balanced_rf = BalancedRandomForestClassifier(\n",
    "    n_estimators=100,  # 기본 트리 수\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "balanced_rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Test 데이터를 사용하여 타겟 변수 예측\n",
    "y_pred_test = balanced_rf.predict(X_test_scaled)\n",
    "\n",
    "# 예측 결과를 Test 데이터프레임에 추가\n",
    "test_df['predicted_target'] = y_pred_test\n",
    "\n",
    "# 예측 결과 확인\n",
    "print(test_df[['predicted_target']].head())\n",
    "\n",
    "# 필요 시 예측 결과를 CSV 파일로 저장\n",
    "# test_df.to_csv('predicted_test_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c8324d35-4029-49e1-b27c-ed6180214c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = test_df['predicted_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a336b5fb-009f-4779-ad0b-958f21d549ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스별 개수: {0: 10937, 1: 6424}\n",
      "클래스별 비율: {0: 0.6299752318414837, 1: 0.3700247681585162}\n"
     ]
    }
   ],
   "source": [
    "analysis = analyze_class_distribution(y_test_pred)\n",
    "\n",
    "print(\"클래스별 개수:\", analysis['class_counts'])\n",
    "print(\"클래스별 비율:\", analysis['class_ratios'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213da6d4-b724-4f07-86ee-dc3f8163d03f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
